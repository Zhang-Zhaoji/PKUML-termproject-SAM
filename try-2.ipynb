{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from segment_anything import sam_model_registry\n",
    "from segment_anything import SamAutomaticMaskGenerator,SamPredictor\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from pycocotools import mask as mask_utils\n",
    "import torch\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "device = \"cuda\"\n",
    "# load default model\n",
    "# Loading the model based on checkpoint\n",
    "sam_model = sam_model_registry[\"vit_h\"](checkpoint=\"./checkpoint/sam_vit_h_4b8939.pth\")\n",
    "sam_model.to(device=device)\n",
    "predictor = SamPredictor(sam_model=sam_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataset\n",
    "import torch.nn.functional as F\n",
    "from torchvision.transforms import Resize\n",
    "from segment_anything import SamPredictor, sam_model_registry, utils\n",
    "\n",
    "custom_dataset = \"./data/dataset_0.json\"\n",
    "optimizer = torch.optim.Adam(sam_model.mask_decoder.parameters())\n",
    "\n",
    "# Set up loss function\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "# Load custom dataset\n",
    "# Here, we should replace 'custom_dataset' with the dataset loader\n",
    "# Define transforms\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "num_epochs = 2\n",
    "for epoch in range(num_epochs):  # num_epochs to be defined\n",
    "    for input_image, box_torch, gt_binary_mask in custom_dataset:\n",
    "        input_image, box_torch, gt_binary_mask = input_image.to(device), box_torch.to(device), gt_binary_mask.to(device)\n",
    "\n",
    "        # Image encoding\n",
    "        with torch.no_grad():\n",
    "            image_embedding = sam_model.image_encoder(input_image)\n",
    "        \n",
    "        # Prompt encoding\n",
    "        with torch.no_grad():\n",
    "            sparse_embeddings, dense_embeddings = sam_model.prompt_encoder(points=None, boxes=box_torch, masks=None)\n",
    "\n",
    "        # Mask decoding\n",
    "        low_res_masks, iou_predictions = sam_model.mask_decoder(\n",
    "            image_embeddings=image_embedding,\n",
    "            image_pe=sam_model.prompt_encoder.get_dense_pe(),\n",
    "            sparse_prompt_embeddings=sparse_embeddings,\n",
    "            dense_prompt_embeddings=dense_embeddings,\n",
    "            multimask_output=False,\n",
    "        )\n",
    "\n",
    "        # Postprocessing\n",
    "        upscaled_masks = sam_model.postprocess_masks(low_res_masks, input_size, original_image_size).to(device)\n",
    "\n",
    "        # Generate binary mask\n",
    "        binary_mask = F.normalize(F.threshold(upscaled_masks, 0.0, 0)).to(device)\n",
    "\n",
    "        # Calculate loss and backpropagate\n",
    "        loss = loss_fn(binary_mask, gt_binary_mask)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# Save the fine-tuned model\n",
    "torch.save(sam_model.state_dict(), 'fine_tuned_sam.pth')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
